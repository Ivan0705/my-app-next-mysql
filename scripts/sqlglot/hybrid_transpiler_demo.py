
#!/usr/bin/env python3
"""
–ì–ò–ë–†–ò–î–ù–´–ô SQL –¢–†–ê–ù–°–ü–ò–õ–Ø–¢–û–† - –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –î–õ–Ø –ö–û–ú–ê–ù–î–´
–°–æ—á–µ—Ç–∞–µ—Ç –ø—Ä–æ—Å—Ç—ã–µ –∑–∞–º–µ–Ω—ã –¥–ª—è –±–∞–∑–æ–≤—ã—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∏ sqlglot –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö
–í–∫–ª—é—á–∞–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Å–ª–æ–∂–Ω—ã–π –ø—Ä–∏–º–µ—Ä SQL
"""

import sys
import re
import time
from typing import List, Dict, Any, Optional
from pathlib import Path

# ==================== –í–°–¢–†–û–ï–ù–ù–´–ô –ü–†–ò–ú–ï–† SQL ====================

COMPLEX_SQL_EXAMPLE = """-- –ü—Ä–∏–º–µ—Ä —Å–ª–æ–∂–Ω–æ–≥–æ SQL —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏
-- –ê–≤—Ç–æ—Ä: –ö–æ–º–∞–Ω–¥–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
-- –î–∞—Ç–∞: 2026

-- –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü
CREATE TABLE departments (
    dept_id INT PRIMARY KEY AUTO_INCREMENT,
    dept_name VARCHAR(100) NOT NULL,
    budget DECIMAL(15,2) DEFAULT 0.00,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE employees (
    emp_id INT PRIMARY KEY AUTO_INCREMENT,
    dept_id INT NOT NULL,
    emp_name VARCHAR(100) NOT NULL,
    salary DECIMAL(10,2),
    hire_date DATE,
    status ENUM('active', 'on_leave', 'terminated') DEFAULT 'active',
    FOREIGN KEY (dept_id) REFERENCES departments(dept_id) ON DELETE CASCADE
);

CREATE TABLE projects (
    project_id INT PRIMARY KEY AUTO_INCREMENT,
    project_name VARCHAR(200) NOT NULL,
    start_date DATE,
    end_date DATE,
    budget DECIMAL(15,2)
);

CREATE TABLE employee_projects (
    emp_id INT,
    project_id INT,
    role VARCHAR(50),
    hours_worked DECIMAL(5,2),
    PRIMARY KEY (emp_id, project_id),
    FOREIGN KEY (emp_id) REFERENCES employees(emp_id),
    FOREIGN KEY (project_id) REFERENCES projects(project_id)
);

-- –ü—Ä–∏–º–µ—Ä 1: –°–ª–æ–∂–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å –æ–∫–æ–Ω–Ω—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏ –∏ CTE
WITH department_stats AS (
    SELECT 
        d.dept_id,
        d.dept_name,
        COUNT(e.emp_id) as employee_count,
        AVG(e.salary) as avg_salary,
        SUM(e.salary) as total_salary
    FROM departments d
    LEFT JOIN employees e ON d.dept_id = e.dept_id
    WHERE e.status = 'active'
    GROUP BY d.dept_id, d.dept_name
),
ranked_departments AS (
    SELECT 
        *,
        RANK() OVER (ORDER BY total_salary DESC) as salary_rank,
        DENSE_RANK() OVER (ORDER BY employee_count DESC) as size_rank
    FROM department_stats
)
SELECT 
    dept_name,
    employee_count,
    ROUND(avg_salary, 2) as avg_salary,
    total_salary,
    salary_rank,
    size_rank,
    CASE 
        WHEN total_salary > 1000000 THEN 'High Budget'
        WHEN total_salary > 500000 THEN 'Medium Budget'
        ELSE 'Low Budget'
    END as budget_category
FROM ranked_departments
ORDER BY salary_rank;

-- –ü—Ä–∏–º–µ—Ä 2: PIVOT-–ø–æ–¥–æ–±–Ω—ã–π –∑–∞–ø—Ä–æ—Å (—ç–º—É–ª—è—Ü–∏—è)
SELECT 
    d.dept_name,
    SUM(CASE WHEN e.status = 'active' THEN 1 ELSE 0 END) as active_employees,
    SUM(CASE WHEN e.status = 'on_leave' THEN 1 ELSE 0 END) as on_leave_employees,
    SUM(CASE WHEN e.status = 'terminated' THEN 1 ELSE 0 END) as terminated_employees,
    COUNT(*) as total_employees
FROM departments d
LEFT JOIN employees e ON d.dept_id = e.dept_id
GROUP BY d.dept_id, d.dept_name
ORDER BY total_employees DESC;

-- –ü—Ä–∏–º–µ—Ä 3: –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π CTE (–∏–µ—Ä–∞—Ä—Ö–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤)
-- –°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤–∏–º –∫–æ–ª–æ–Ω–∫—É manager_id
ALTER TABLE employees ADD COLUMN manager_id INT NULL;
ALTER TABLE employees ADD FOREIGN KEY (manager_id) REFERENCES employees(emp_id);

-- –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–µ—Ä–∞—Ä—Ö–∏–∏
WITH RECURSIVE employee_hierarchy AS (
    -- –Ø–∫–æ—Ä—å —Ä–µ–∫—É—Ä—Å–∏–∏: —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ –±–µ–∑ –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ (–≤–µ—Ä—Ö–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å)
    SELECT 
        emp_id,
        emp_name,
        manager_id,
        1 as level,
        CAST(emp_name AS CHAR(500)) as hierarchy_path
    FROM employees
    WHERE manager_id IS NULL
    
    UNION ALL
    
    -- –†–µ–∫—É—Ä—Å–∏–≤–Ω–∞—è —á–∞—Å—Ç—å
    SELECT 
        e.emp_id,
        e.emp_name,
        e.manager_id,
        eh.level + 1,
        CONCAT(eh.hierarchy_path, ' -> ', e.emp_name)
    FROM employees e
    INNER JOIN employee_hierarchy eh ON e.manager_id = eh.emp_id
    WHERE eh.level < 10  -- –∑–∞—â–∏—Ç–∞ –æ—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–π —Ä–µ–∫—É—Ä—Å–∏–∏
)
SELECT 
    emp_id,
    emp_name,
    level,
    hierarchy_path
FROM employee_hierarchy
ORDER BY level, emp_name;

-- –ü—Ä–∏–º–µ—Ä 4: –°–ª–æ–∂–Ω—ã–π ROLLUP
SELECT 
    COALESCE(d.dept_name, 'All Departments') as department,
    COALESCE(YEAR(e.hire_date), 'All Years') as hire_year,
    COUNT(e.emp_id) as employees_hired,
    ROUND(AVG(e.salary), 2) as avg_salary,
    SUM(e.salary) as total_salary
FROM departments d
LEFT JOIN employees e ON d.dept_id = e.dept_id
WHERE e.status = 'active'
GROUP BY d.dept_name, YEAR(e.hire_date) WITH ROLLUP
HAVING total_salary IS NOT NULL
ORDER BY d.dept_name, hire_year;

-- –ü—Ä–∏–º–µ—Ä 5: –û–∫–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Å PARTITION BY
SELECT 
    e.emp_id,
    e.emp_name,
    d.dept_name,
    e.salary,
    ROUND(AVG(e.salary) OVER (PARTITION BY e.dept_id), 2) as dept_avg_salary,
    ROUND(e.salary - AVG(e.salary) OVER (PARTITION BY e.dept_id), 2) as diff_from_avg,
    RANK() OVER (PARTITION BY e.dept_id ORDER BY e.salary DESC) as salary_rank_in_dept,
    PERCENT_RANK() OVER (PARTITION BY e.dept_id ORDER BY e.salary) as salary_percentile
FROM employees e
JOIN departments d ON e.dept_id = d.dept_id
WHERE e.status = 'active'
ORDER BY d.dept_name, salary_rank_in_dept;

-- –ü—Ä–∏–º–µ—Ä 6: –ü–æ–¥–∑–∞–ø—Ä–æ—Å—ã –≤ SELECT, FROM, WHERE
SELECT 
    d.dept_name,
    (SELECT COUNT(*) FROM employees e WHERE e.dept_id = d.dept_id AND e.status = 'active') as active_count,
    (SELECT AVG(salary) FROM employees e WHERE e.dept_id = d.dept_id AND e.status = 'active') as avg_salary,
    (SELECT MAX(salary) FROM employees e WHERE e.dept_id = d.dept_id AND e.status = 'active') as max_salary,
    (SELECT emp_name FROM employees e 
     WHERE e.dept_id = d.dept_id 
     AND e.status = 'active' 
     ORDER BY salary DESC LIMIT 1) as highest_paid_employee
FROM departments d
WHERE EXISTS (
    SELECT 1 FROM employees e 
    WHERE e.dept_id = d.dept_id 
    AND e.status = 'active'
)
ORDER BY d.dept_name;"""

# ==================== –ö–û–ù–°–¢–ê–ù–¢–´ ====================

DIALECT_NOTES = {
    "snowflake": "Snowflake: No FOREIGN KEY enforcement, AUTOINCREMENT for auto-increment, NUMBER for numeric types",
    "bigquery": "BigQuery: No FOREIGN KEY support, STRING instead of VARCHAR, NUMERIC for decimals",
    "oracle": "Oracle: Use SEQUENCES or GENERATED AS IDENTITY for auto-increment, VARCHAR2 instead of VARCHAR",
    "postgres": "PostgreSQL: GENERATED BY DEFAULT AS IDENTITY for auto-increment, TIMESTAMPTZ for timestamps",
    "mssql": "SQL Server: IDENTITY for auto-increment, DATETIME2 for timestamps, [] for identifiers",
    "sqlite": "SQLite: TEXT for strings and dates, REAL for decimals, AUTOINCREMENT for auto-increment",
    "redshift": "Redshift: Based on PostgreSQL, IDENTITY for auto-increment, limited FOREIGN KEY",
    "mysql": "MySQL: Standard syntax with AUTO_INCREMENT"
}

# ==================== –î–µ—Ç–µ–∫—Ç–æ—Ä —Å–ª–æ–∂–Ω—ã—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π ====================

def detect_complex_features(sql: str) -> Dict[str, bool]:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Å–ª–æ–∂–Ω—ã—Ö SQL –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π"""
    sql_upper = sql.upper()
    
    features = {
        "has_window_functions": any(x in sql_upper for x in [
            "OVER(", "ROW_NUMBER()", "RANK()", "DENSE_RANK()", 
            "LEAD(", "LAG(", "FIRST_VALUE(", "LAST_VALUE(",
            "PARTITION BY", "ORDER BY"
        ]),
        "has_cte": "WITH" in sql_upper and ("RECURSIVE" in sql_upper or "AS (" in sql_upper),
        "has_recursive": "WITH RECURSIVE" in sql_upper,
        "has_rollup": "WITH ROLLUP" in sql_upper or "GROUPING SETS" in sql_upper,
        "has_pivot": "PIVOT" in sql_upper or "UNPIVOT" in sql_upper,
        "has_case_when": "CASE WHEN" in sql_upper or "CASE" in sql_upper,
        "has_subqueries": any(f"({keyword}" in sql_upper for keyword in [
            "SELECT", "FROM", "WHERE", "HAVING"
        ]),
        "has_json_functions": any(x in sql_upper for x in [
            "JSON_", "->>", "->", "#>", "#>>"
        ]),
        "has_string_functions": any(x in sql_upper for x in [
            "CONCAT(", "SUBSTRING(", "REGEXP_", "LIKE"
        ]),
        "has_date_functions": any(x in sql_upper for x in [
            "DATE_ADD", "DATE_SUB", "DATEDIFF", "YEAR(", "MONTH("
        ]),
        "has_aggregate_functions": any(x in sql_upper for x in [
            "SUM(", "AVG(", "COUNT(", "MAX(", "MIN("
        ]),
    }
    
    features["is_complex"] = any(features[key] for key in [
        "has_window_functions", "has_cte", "has_recursive", 
        "has_rollup", "has_pivot"
    ])
    
    return features

# ==================== –ü—Ä–æ—Å—Ç—ã–µ –∑–∞–º–µ–Ω—ã (–¥–ª—è –±–∞–∑–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤) ====================

def simple_dialect_conversion(sql: str, dialect: str) -> str:
    """–ü—Ä–æ—Å—Ç–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–ª—è –±–∞–∑–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (CREATE TABLE, –ø—Ä–æ—Å—Ç—ã–µ SELECT)"""
    result = sql
    
    # –û–±—â–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –¥–∏–∞–ª–µ–∫—Ç–æ–≤
    result = re.sub(r'\);+', ');', result)  # –£–±–∏—Ä–∞–µ–º –¥–≤–æ–π–Ω—ã–µ —Ç–æ—á–∫–∏ —Å –∑–∞–ø—è—Ç–æ–π
    result = re.sub(r'\s{2,}', ' ', result)  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    
    if dialect == "postgres":
        result = re.sub(r'\bAUTO_INCREMENT\b', 'GENERATED BY DEFAULT AS IDENTITY', result, flags=re.IGNORECASE)
        result = re.sub(r'\bINT\b', 'INTEGER', result, flags=re.IGNORECASE)
        result = re.sub(r'\bTIMESTAMP\b', 'TIMESTAMPTZ', result, flags=re.IGNORECASE)
        result = re.sub(r'`([^`]+)`', r'"\1"', result)
        result = re.sub(r'\bDATETIME\b', 'TIMESTAMP', result, flags=re.IGNORECASE)
        result = re.sub(r'ON UPDATE CURRENT_TIMESTAMP', '', result, flags=re.IGNORECASE)
        
    elif dialect == "snowflake":
        result = re.sub(r'\bAUTO_INCREMENT\b', 'AUTOINCREMENT', result, flags=re.IGNORECASE)
        result = re.sub(r'\bINT\b', 'NUMBER', result, flags=re.IGNORECASE)
        result = re.sub(r'\bDECIMAL\s*\(\s*(\d+)\s*,\s*(\d+)\s*\)', r'NUMBER(\1,\2)', result, flags=re.IGNORECASE)
        result = re.sub(r'\bDATETIME\b', 'TIMESTAMP_NTZ', result, flags=re.IGNORECASE)
        result = re.sub(r'DEFAULT CURRENT_TIMESTAMP(?!\()', 'DEFAULT CURRENT_TIMESTAMP()', result, flags=re.IGNORECASE)
        result = re.sub(r'ON UPDATE CURRENT_TIMESTAMP', '', result, flags=re.IGNORECASE)
        
    elif dialect == "bigquery":
        result = re.sub(r'\bAUTO_INCREMENT\b', '', result, flags=re.IGNORECASE)
        result = re.sub(r'\bINT\b', 'INT64', result, flags=re.IGNORECASE)
        result = re.sub(r'\bVARCHAR\s*\(\s*(\d+)\s*\)', r'STRING', result, flags=re.IGNORECASE)
        result = re.sub(r'\bDECIMAL\s*\(\s*(\d+)\s*,\s*(\d+)\s*\)', r'NUMERIC(\1,\2)', result, flags=re.IGNORECASE)
        result = re.sub(r'\bDATETIME\b', 'TIMESTAMP', result, flags=re.IGNORECASE)
        result = re.sub(r'DEFAULT CURRENT_TIMESTAMP(?!\()', 'DEFAULT CURRENT_TIMESTAMP()', result, flags=re.IGNORECASE)
        
        # –£–±–∏—Ä–∞–µ–º FOREIGN KEY –¥–ª—è BigQuery –ø–æ–ª–Ω–æ—Å—Ç—å—é
        result = re.sub(r',?\s*FOREIGN KEY\s*\([^)]+\)\s*REFERENCES\s*\w+\s*\([^)]+\)(\s*ON DELETE\s+\w+)?', 
                       '', result, flags=re.IGNORECASE)
        
        # –£–±–∏—Ä–∞–µ–º ALTER TABLE —Å FOREIGN KEY –¥–ª—è BigQuery
        if 'ALTER TABLE' in result.upper() and 'ADD FOREIGN KEY' in result.upper():
            result = ''
            
        result = re.sub(r'\bENUM\s*\([^)]+\)', 'STRING', result, flags=re.IGNORECASE)
        
    elif dialect == "oracle":
        result = re.sub(r'\bAUTO_INCREMENT\b', '', result, flags=re.IGNORECASE)
        result = re.sub(r'\bINT\b', 'NUMBER(10)', result, flags=re.IGNORECASE)
        result = re.sub(r'\bVARCHAR\s*\(\s*', 'VARCHAR2(', result, flags=re.IGNORECASE)
        result = re.sub(r'\bDECIMAL\s*\(\s*(\d+)\s*,\s*(\d+)\s*\)', r'NUMBER(\1,\2)', result, flags=re.IGNORECASE)
        result = re.sub(r'\bTIMESTAMP\b', 'TIMESTAMP', result, flags=re.IGNORECASE)
        result = re.sub(r'\bDATETIME\b', 'DATE', result, flags=re.IGNORECASE)
        result = re.sub(r'DEFAULT CURRENT_TIMESTAMP', 'DEFAULT SYSTIMESTAMP', result, flags=re.IGNORECASE)
        result = re.sub(r'\bENUM\s*\([^)]+\)', 'VARCHAR2(20)', result, flags=re.IGNORECASE)
        
    elif dialect == "mssql":
        result = re.sub(r'\bAUTO_INCREMENT\b', 'IDENTITY(1,1)', result, flags=re.IGNORECASE)
        result = re.sub(r'\bTIMESTAMP\b', 'DATETIME2', result, flags=re.IGNORECASE)
        result = re.sub(r'\bDATETIME\b', 'DATETIME2', result, flags=re.IGNORECASE)
        result = re.sub(r'\bCURRENT_TIMESTAMP\b', 'GETDATE()', result, flags=re.IGNORECASE)
        result = re.sub(r'`([^`]+)`', r'[\1]', result)
        result = re.sub(r'\bENUM\s*\([^)]+\)', 'VARCHAR(20)', result, flags=re.IGNORECASE)
        
        # MSSQL –∏—Å–ø–æ–ª—å–∑—É–µ—Ç INT, –∞ –Ω–µ INT64
        result = re.sub(r'\bINT64\b', 'INT', result, flags=re.IGNORECASE)
        result = re.sub(r'\bNUMERIC\b', 'DECIMAL', result, flags=re.IGNORECASE)
        result = re.sub(r'\bSTRING\b', 'VARCHAR', result, flags=re.IGNORECASE)
        
    elif dialect == "sqlite":
        result = re.sub(r'\bAUTO_INCREMENT\b', 'AUTOINCREMENT', result, flags=re.IGNORECASE)
        result = re.sub(r'\bINT\b', 'INTEGER', result, flags=re.IGNORECASE)
        result = re.sub(r'\bVARCHAR\s*\(\s*(\d+)\s*\)', r'TEXT', result, flags=re.IGNORECASE)
        result = re.sub(r'\bDECIMAL\s*\(\s*(\d+)\s*,\s*(\d+)\s*\)', r'REAL', result, flags=re.IGNORECASE)
        result = re.sub(r'\bTIMESTAMP\b', 'TEXT', result, flags=re.IGNORECASE)
        result = re.sub(r'\bDATETIME\b', 'TEXT', result, flags=re.IGNORECASE)
        result = re.sub(r'\bDATE\b', 'TEXT', result, flags=re.IGNORECASE)
        result = re.sub(r'\bENUM\s*\([^)]+\)', 'TEXT', result, flags=re.IGNORECASE)
        
    elif dialect == "redshift":
        result = re.sub(r'\bAUTO_INCREMENT\b', 'IDENTITY(1,1)', result, flags=re.IGNORECASE)
        result = re.sub(r'\bINT\b', 'INTEGER', result, flags=re.IGNORECASE)
        result = re.sub(r'\bTIMESTAMP\b', 'TIMESTAMP', result, flags=re.IGNORECASE)
        result = re.sub(r'\bDATETIME\b', 'TIMESTAMP', result, flags=re.IGNORECASE)
        result = re.sub(r'\bCURRENT_TIMESTAMP\b', 'GETDATE()', result, flags=re.IGNORECASE)
        result = re.sub(r'\bENUM\s*\([^)]+\)', 'VARCHAR(20)', result, flags=re.IGNORECASE)
    
    return result

# ==================== SQLGlot —Ç—Ä–∞–Ω—Å–ø–∏–ª—è—Ü–∏—è (–¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤) ====================

def transpile_with_sqlglot(sql: str, from_dialect: str, to_dialect: str) -> str:
    """–ò—Å–ø–æ–ª—å–∑—É–µ—Ç sqlglot –¥–ª—è —Ç—Ä–∞–Ω—Å–ø–∏–ª—è—Ü–∏–∏ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
    try:
        import sqlglot
        import sqlglot.expressions as exp
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –¥–∏–∞–ª–µ–∫—Ç–æ–≤
        dialect_mapping = {
            "mssql": "tsql",
            "redshift": "redshift",
            "mysql": "mysql",
            "postgres": "postgres",
            "bigquery": "bigquery",
            "snowflake": "snowflake",
            "oracle": "oracle",
            "sqlite": "sqlite"
        }
        
        read_dialect = dialect_mapping.get(from_dialect, from_dialect)
        write_dialect = dialect_mapping.get(to_dialect, to_dialect)
        
        # –ü–∞—Ä—Å–∏–º –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ–º
        parsed = sqlglot.parse_one(sql, read=read_dialect)
        
        if not parsed:
            return sql
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –±–∞–∑–æ–≤—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
        transformed = parsed.transform(lambda node: transform_sqlglot_node(node, to_dialect))
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º SQL —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        result = transformed.sql(dialect=write_dialect, pretty=True)  # –ò–∑–º–µ–Ω–µ–Ω–æ –Ω–∞ pretty=True
        
        # –ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞
        result = post_process_sqlglot_result(result, to_dialect)
        
        return result
        
    except ImportError:
        return f"-- ERROR: sqlglot not installed. Install with: pip install sqlglot\n-- Original query:\n{sql}"
    except Exception as e:
        error_msg = str(e)
        if "Parse error" in error_msg:
            return f"-- SQLGlot parse error. Using fallback conversion.\n-- Original query:\n{sql}"
        else:
            return f"-- ERROR in sqlglot transpilation: {error_msg[:200]}\n-- Original query:\n{sql}"


def transform_sqlglot_node(node, to_dialect: str):
    """–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —É–∑–ª—ã AST –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –¥–∏–∞–ª–µ–∫—Ç–æ–≤"""
    import sqlglot.expressions as exp
    
    if isinstance(node, exp.DataType):
        return transform_sqlglot_datatype(node, to_dialect)
    
    # –î–ª—è –æ–∫–æ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –¥–æ–±–∞–≤–ª—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
    if isinstance(node, exp.Window):
        return transform_sqlglot_window(node, to_dialect)
    
    return node

def transform_sqlglot_datatype(datatype, to_dialect: str):
    """–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ sqlglot"""
    import sqlglot.expressions as exp
    
    dtype_str = str(datatype).upper()
    
    if to_dialect == "postgres":
        if "INT" in dtype_str and "INTEGER" not in dtype_str:
            return exp.DataType(this="INTEGER")
        elif "DATETIME" in dtype_str:
            return exp.DataType(this="TIMESTAMPTZ")
            
    elif to_dialect == "bigquery":
        if "INT" in dtype_str:
            return exp.DataType(this="INT64")
        elif "VARCHAR" in dtype_str or "CHAR" in dtype_str:
            return exp.DataType(this="STRING")
        elif "DECIMAL" in dtype_str or "NUMERIC" in dtype_str:
            return exp.DataType(this="NUMERIC")
            
    elif to_dialect == "oracle":
        if "INT" in dtype_str or "INTEGER" in dtype_str:
            return exp.DataType.build("NUMBER(10)")
        elif "VARCHAR" in dtype_str:
            return exp.DataType.build("VARCHAR2")
            
    elif to_dialect == "snowflake":
        if "INT" in dtype_str:
            return exp.DataType(this="NUMBER")
        elif "DATETIME" in dtype_str:
            return exp.DataType(this="TIMESTAMP_NTZ")
            
    return datatype

def transform_sqlglot_window(window_node, to_dialect: str):
    """–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –æ–∫–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –¥–∏–∞–ª–µ–∫—Ç–æ–≤"""
    import sqlglot.expressions as exp
    
    # –î–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –¥–∏–∞–ª–µ–∫—Ç–æ–≤ –Ω—É–∂–Ω—ã —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–∫–æ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
    if to_dialect == "bigquery":
        # BigQuery —Ç—Ä–µ–±—É–µ—Ç —è–≤–Ω–æ–≥–æ —É–∫–∞–∑–∞–Ω–∏—è WINDOW –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–ª—É—á–∞—è—Ö
        pass
    elif to_dialect == "oracle":
        # Oracle –∏–º–µ–µ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–µ –æ–∫–æ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
        pass
    
    return window_node

def post_process_sqlglot_result(sql: str, dialect: str) -> str:
    """–ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ sqlglot"""
    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    sql = re.sub(r'\s{2,}', ' ', sql)
    sql = re.sub(r'\s+,', ',', sql)
    sql = re.sub(r',\s*', ', ', sql)
    
    # –£–±–∏—Ä–∞–µ–º –¥–≤–æ–π–Ω—ã–µ —Ç–æ—á–∫–∏ —Å –∑–∞–ø—è—Ç–æ–π
    sql = re.sub(r'\);+', ');', sql)
    
    # –î–∏–∞–ª–µ–∫—Ç-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–∞–≤—ã—á–µ–∫
    if dialect == "bigquery":
        sql = re.sub(r'"([^"]+)"', r'`\1`', sql)
        # –£–±–∏—Ä–∞–µ–º FOREIGN KEY –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –¥–ª—è BigQuery
        lines = sql.split('\n')
        cleaned_lines = []
        for line in lines:
            if 'FOREIGN KEY' in line.upper() and not line.strip().startswith('--'):
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º FOREIGN KEY –¥–ª—è BigQuery
            cleaned_lines.append(line)
        sql = '\n'.join(cleaned_lines)
        
    elif dialect in ["postgres", "oracle", "redshift"]:
        sql = re.sub(r'`([^`]+)`', r'"\1"', sql)
    elif dialect == "mssql":
        sql = re.sub(r'`([^`]+)`', r'[\1]', sql)
        sql = re.sub(r'"([^"]+)"', r'[\1]', sql)
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ç–∏–ø—ã –¥–ª—è MSSQL
        sql = re.sub(r'\bINT64\b', 'INT', sql, flags=re.IGNORECASE)
        sql = re.sub(r'\bNUMERIC\b', 'DECIMAL', sql, flags=re.IGNORECASE)
        sql = re.sub(r'\bSTRING\b', 'VARCHAR', sql, flags=re.IGNORECASE)
    
    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö —Ç–∏–ø–æ–≤
    sql = re.sub(r'NUMBER\s*\(\s*(\d+)\s*,\s*(\d+)\s*\)', r'NUMBER(\1,\2)', sql, flags=re.IGNORECASE)
    sql = re.sub(r'DECIMAL\s*\(\s*(\d+)\s*,\s*(\d+)\s*\)', r'DECIMAL(\1,\2)', sql, flags=re.IGNORECASE)
    sql = re.sub(r'NUMERIC\s*\(\s*(\d+)\s*,\s*(\d+)\s*\)', r'NUMERIC(\1,\2)', sql, flags=re.IGNORECASE)
    
    return sql.strip()

# ==================== –ì–∏–±—Ä–∏–¥–Ω—ã–π —Ç—Ä–∞–Ω—Å–ø–∏–ª—è—Ç–æ—Ä ====================

def hybrid_transpile(sql: str, from_dialect: str, to_dialect: str) -> Dict[str, Any]:
    """–ì–∏–±—Ä–∏–¥–Ω–∞—è —Ç—Ä–∞–Ω—Å–ø–∏–ª—è—Ü–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–∞"""
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º SQL
    features = detect_complex_features(sql)
    warnings = []
    method_used = {"simple": 0, "sqlglot": 0}
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è
    statements = split_sql_statements(sql)
    transpiled_statements = []
    
    for stmt in statements:
        if not stmt.strip():
            transpiled_statements.append("")
            continue
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ ALTER TABLE –¥–ª—è BigQuery
        if to_dialect == "bigquery" and "ALTER TABLE" in stmt.upper() and "ADD FOREIGN KEY" in stmt.upper():
            continue
            
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —Å–ª–æ–∂–Ω—ã–π –ª–∏ —ç—Ç–æ –∑–∞–ø—Ä–æ—Å
        stmt_features = detect_complex_features(stmt)
        
        if stmt_features["is_complex"]:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º sqlglot –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            method_used["sqlglot"] += 1
            transpiled = transpile_with_sqlglot(stmt, from_dialect, to_dialect)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –æ –º–µ—Ç–æ–¥–µ (—Ç–æ–ª—å–∫–æ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏)
            if not transpiled.strip().startswith("--"):
                transpiled = f"-- [Using sqlglot for complex features]\n{transpiled}"
                
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—ã–µ –∑–∞–º–µ–Ω—ã –¥–ª—è –±–∞–∑–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            method_used["simple"] += 1
            transpiled = simple_dialect_conversion(stmt, to_dialect)
        
        # –î–∏–∞–ª–µ–∫—Ç-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞
        transpiled = apply_dialect_specific_processing(transpiled, to_dialect)
        
        # –£–±–∏—Ä–∞–µ–º –¥–≤–æ–π–Ω—ã–µ —Ç–æ—á–∫–∏ —Å –∑–∞–ø—è—Ç–æ–π
        transpiled = re.sub(r'\);+', ');', transpiled)
        
        transpiled_statements.append(transpiled)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥
    if method_used["sqlglot"] > method_used["simple"]:
        primary_method = "sqlglot"
    else:
        primary_method = "simple"
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    result_sql = "\n\n".join([s for s in transpiled_statements if s.strip()])
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Ç–æ—á–∫—É —Å –∑–∞–ø—è—Ç–æ–π –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if result_sql.strip() and not result_sql.rstrip().endswith(';'):
        result_sql = result_sql.rstrip() + ';'
    
    return {
        "success": True,
        "transpiled": [result_sql],
        "from_dialect": from_dialect,
        "to_dialect": to_dialect,
        "features_detected": features,
        "methods_used": method_used,
        "primary_method": primary_method,
        "total_statements": len(statements),
        "warnings": warnings,
        "note": DIALECT_NOTES.get(to_dialect, "Check dialect-specific documentation")
    }


def split_sql_statements(sql: str) -> List[str]:
    """–†–∞–∑–±–∏–≤–∞–µ—Ç SQL –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è"""
    statements = []
    current = ""
    depth = 0
    in_quote = False
    quote_char = None
    
    for char in sql + ';':
        if char in ("'", '"', '`'):
            if not in_quote:
                in_quote = True
                quote_char = char
            elif quote_char == char:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏
                if len(current) > 0 and current[-1] == '\\':
                    pass  # –≠—Ç–æ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–∞–≤—ã—á–∫–∞
                else:
                    in_quote = False
                    quote_char = None
        
        if not in_quote:
            if char == '(':
                depth += 1
            elif char == ')':
                depth -= 1
        
        current += char
        
        if char == ';' and not in_quote and depth == 0:
            stmt = current.strip()
            if stmt and stmt != ';':
                statements.append(stmt)
            current = ""
    
    if current.strip():
        statements.append(current.strip())
    
    return statements

def apply_dialect_specific_processing(sql: str, dialect: str) -> str:
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –¥–∏–∞–ª–µ–∫—Ç-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—É—é –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫—É"""
    result = sql
    
    if dialect == "snowflake" and "FOREIGN KEY" in result.upper():
        if not result.strip().startswith('--'):
            result = "-- Snowflake doesn't enforce FOREIGN KEY constraints:\n" + result
    
    elif dialect == "bigquery" and "FOREIGN KEY" in result.upper():
        lines = result.split('\n')
        new_lines = []
        for line in lines:
            if 'FOREIGN KEY' in line.upper() and not line.strip().startswith('--'):
                new_lines.append(f"-- BigQuery doesn't support: {line.strip()}")
            else:
                new_lines.append(line)
        result = '\n'.join(new_lines)
    
    elif dialect == "sqlite" and "FOREIGN KEY" in result.upper():
        if "PRAGMA foreign_keys" not in result.upper():
            lines = result.split('\n')
            # –î–æ–±–∞–≤–ª—è–µ–º PRAGMA —Ç–æ–ª—å–∫–æ –≤ –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞
            if not any("PRAGMA foreign_keys" in line.upper() for line in lines[:10]):
                result = "-- SQLite requires PRAGMA foreign_keys = ON for FK support\n" + \
                        "PRAGMA foreign_keys = ON;\n\n" + result
    
    return result

# ==================== –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ====================

def show_original_example():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–∏–º–µ—Ä SQL"""
    print("üìÑ –û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ô –ü–†–ò–ú–ï–† SQL (MySQL):")
    print("=" * 80)
    print(COMPLEX_SQL_EXAMPLE)
    print("=" * 80)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä
    features = detect_complex_features(COMPLEX_SQL_EXAMPLE)
    
    print("\nüìä –ê–ù–ê–õ–ò–ó –ü–†–ò–ú–ï–†–ê:")
    print("-" * 40)
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—Ä–∞–∂–µ–Ω–∏–π: {len(split_sql_statements(COMPLEX_SQL_EXAMPLE))}")
    print("\n–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —Å–ª–æ–∂–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:")
    for feature, has_it in features.items():
        if has_it and feature.startswith("has_"):
            print(f"  ‚úÖ {feature.replace('has_', '').replace('_', ' ').title()}")
    
    print(f"\n–û–±—â–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å: {'–í–´–°–û–ö–ê–Ø' if features['is_complex'] else '–ù–ò–ó–ö–ê–Ø'}")

def show_transformation_comparison(dialect: str = "postgres"):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏ —Ç—Ä–∞–Ω—Å–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–¥–∞"""
    print(f"\nüîÑ –¢–†–ê–ù–°–§–û–†–ú–ê–¶–ò–Ø –í {dialect.upper()}:")
    print("=" * 80)
    
    # –¢—Ä–∞–Ω—Å–ø–∏–ª–∏—Ä—É–µ–º
    start_time = time.time()
    result = hybrid_transpile(COMPLEX_SQL_EXAMPLE, "mysql", dialect)
    elapsed = time.time() - start_time
    
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è: {elapsed:.3f} —Å–µ–∫")
    print(f"üõ†Ô∏è  –ú–µ—Ç–æ–¥—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã: {result['methods_used']}")
    print(f"üéØ –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥: {result['primary_method']}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    print(f"\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –§–†–ê–ì–ú–ï–ù–¢–û–í:")
    print("-" * 40)
    
    original_statements = split_sql_statements(COMPLEX_SQL_EXAMPLE)
    converted_statements = split_sql_statements(result["transpiled"][0])
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤
    examples_to_show = min(5, len(original_statements))
    
    for i in range(examples_to_show):
        if i < len(original_statements) and i < len(converted_statements):
            orig = original_statements[i]
            conv = converted_statements[i]
            
            if orig.strip() and conv.strip():
                print(f"\n–ü—Ä–∏–º–µ—Ä {i+1}:")
                print(f"–û–†–ò–ì–ò–ù–ê–õ (MySQL):")
                print("-" * 40)
                print(orig[:200] + "..." if len(orig) > 200 else orig)
                print(f"\n–ö–û–ù–í–ï–†–¢–ò–†–û–í–ê–ù–ù–û ({dialect}):")
                print("-" * 40)
                print(conv[:200] + "..." if len(conv) > 200 else conv)
                print()

def show_full_transformation(dialect: str = "postgres"):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–æ–ª–Ω—É—é —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é"""
    print(f"\nüìã –ü–û–õ–ù–ê–Ø –¢–†–ê–ù–°–§–û–†–ú–ê–¶–ò–Ø –í {dialect.upper()}:")
    print("=" * 80)
    
    result = hybrid_transpile(COMPLEX_SQL_EXAMPLE, "mysql", dialect)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
    output_file = f"converted_to_{dialect}.sql"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(result["transpiled"][0])
    
    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_file}")
    print("\nüìÑ –†–ï–ó–£–õ–¨–¢–ê–¢ (–ø–µ—Ä–≤—ã–µ 30 —Å—Ç—Ä–æ–∫):")
    print("-" * 80)
    
    lines = result["transpiled"][0].split('\n')[:30]
    for i, line in enumerate(lines, 1):
        print(f"{i:3}: {line}")
    
    if len(result["transpiled"][0].split('\n')) > 30:
        print("... (–ø–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–∞–π–ª–µ)")
    
    print(f"\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"  ‚Ä¢ –í—Å–µ–≥–æ –≤—ã—Ä–∞–∂–µ–Ω–∏–π: {result['total_statements']}")
    print(f"  ‚Ä¢ –ü—Ä–æ—Å—Ç—ã–µ –∑–∞–º–µ–Ω—ã: {result['methods_used']['simple']}")
    print(f"  ‚Ä¢ SQLGlot –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è: {result['methods_used']['sqlglot']}")
    print(f"  ‚Ä¢ –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥: {result['primary_method']}")

def run_all_dialects_demo():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é –¥–ª—è –≤—Å–µ—Ö –¥–∏–∞–ª–µ–∫—Ç–æ–≤"""
    print("üöÄ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –î–õ–Ø –í–°–ï–• –î–ò–ê–õ–ï–ö–¢–û–í")
    print("=" * 80)
    
    dialects = ["postgres", "bigquery", "snowflake", "oracle", "mssql", "sqlite", "redshift"]
    
    for dialect in dialects:
        print(f"\nüéØ –ö–û–ù–í–ï–†–¢–ê–¶–ò–Ø –í {dialect.upper()}:")
        print("-" * 40)
        
        start_time = time.time()
        result = hybrid_transpile(COMPLEX_SQL_EXAMPLE, "mysql", dialect)
        elapsed = time.time() - start_time
        
        print(f"  –í—Ä–µ–º—è: {elapsed:.3f} —Å–µ–∫")
        print(f"  –ú–µ—Ç–æ–¥—ã: {result['methods_used']}")
        print(f"  –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥: {result['primary_method']}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        output_file = f"converted_to_{dialect}.sql"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(result["transpiled"][0])
        
        print(f"  –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_file}")

def run_performance_demo():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    print("‚ö° –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò")
    print("=" * 80)
    
    # –ü—Ä–æ—Å—Ç—ã–µ –∏ —Å–ª–æ–∂–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    simple_query = "CREATE TABLE test (id INT PRIMARY KEY AUTO_INCREMENT, name VARCHAR(100));"
    complex_query = """
WITH cte AS (
    SELECT 1 as n UNION ALL SELECT n + 1 FROM cte WHERE n < 10
)
SELECT n, RANK() OVER (ORDER BY n) as rank FROM cte;
    """
    
    print("\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –°–ö–û–†–û–°–¢–ò:")
    print("-" * 40)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ sqlglot
    try:
        import sqlglot
        sqlglot_available = True
    except ImportError:
        sqlglot_available = False
        print("‚ö†Ô∏è  SQLGlot –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    if sqlglot_available:
        # –¢–µ—Å—Ç –ø—Ä–æ—Å—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        print("\n1. –ü–†–û–°–¢–û–ô –ó–ê–ü–†–û–° (CREATE TABLE):")
        start_time = time.time()
        for _ in range(100):
            simple_dialect_conversion(simple_query, "postgres")
        simple_time = time.time() - start_time
        print(f"   –ü—Ä–æ—Å—Ç—ã–µ –∑–∞–º–µ–Ω—ã (100 –∏—Ç–µ—Ä–∞—Ü–∏–π): {simple_time:.3f} —Å–µ–∫")
        print(f"   –°–∫–æ—Ä–æ—Å—Ç—å: {100/simple_time:.1f} –∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫")
        
        # –¢–µ—Å—Ç —Å–ª–æ–∂–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ—Å—Ç—ã–µ –∑–∞–º–µ–Ω—ã (–Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ, –Ω–æ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)
        start_time = time.time()
        for _ in range(100):
            simple_dialect_conversion(complex_query, "postgres")
        complex_simple_time = time.time() - start_time
        
        # –¢–µ—Å—Ç —Å–ª–æ–∂–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ sqlglot
        start_time = time.time()
        for _ in range(100):
            transpile_with_sqlglot(complex_query, "mysql", "postgres")
        complex_sqlglot_time = time.time() - start_time
        
        print(f"\n2. –°–õ–û–ñ–ù–´–ô –ó–ê–ü–†–û–° (CTE + –æ–∫–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏):")
        print(f"   –ü—Ä–æ—Å—Ç—ã–µ –∑–∞–º–µ–Ω—ã (100 –∏—Ç–µ—Ä–∞—Ü–∏–π): {complex_simple_time:.3f} —Å–µ–∫")
        print(f"   SQLGlot (100 –∏—Ç–µ—Ä–∞—Ü–∏–π): {complex_sqlglot_time:.3f} —Å–µ–∫")
        print(f"\nüìà –í–´–í–û–î–´:")
        print(f"   ‚Ä¢ –ü—Ä–æ—Å—Ç—ã–µ –∑–∞–ø—Ä–æ—Å—ã: –ø—Ä–æ—Å—Ç—ã–µ –∑–∞–º–µ–Ω—ã –≤ {complex_sqlglot_time/simple_time:.1f}√ó –±—ã—Å—Ç—Ä–µ–µ")
        print(f"   ‚Ä¢ –°–ª–æ–∂–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã: SQLGlot –¥–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
        print(f"   ‚Ä¢ –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –æ–ø—Ç–∏–º–∞–ª–µ–Ω –¥–ª—è —Å–º–µ—à–∞–Ω–Ω—ã—Ö –Ω–∞–≥—Ä—É–∑–æ–∫")

# ==================== –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ====================

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    print("üöÄ –ì–ò–ë–†–ò–î–ù–´–ô SQL –¢–†–ê–ù–°–ü–ò–õ–Ø–¢–û–† - –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø")
    print("=" * 60)
    print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
    print("  1. python hybrid_transpiler_demo.py show           # –ü–æ–∫–∞–∑–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–∏–º–µ—Ä")
    print("  2. python hybrid_transpiler_demo.py compare        # –°—Ä–∞–≤–Ω–∏—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è")
    print("  3. python hybrid_transpiler_demo.py full <–¥–∏–∞–ª–µ–∫—Ç> # –ü–æ–ª–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è")
    print("  4. python hybrid_transpiler_demo.py all            # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –≤–æ –≤—Å–µ –¥–∏–∞–ª–µ–∫—Ç—ã")
    print("  5. python hybrid_transpiler_demo.py perf           # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    print("  6. python hybrid_transpiler_demo.py convert <–¥–∏–∞–ª–µ–∫—Ç> # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ")
    print("\n–î–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∏–∞–ª–µ–∫—Ç—ã: postgres, bigquery, snowflake, oracle, mssql, sqlite, redshift")
    
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == "show":
            show_original_example()
        
        elif command == "compare":
            dialect = sys.argv[2] if len(sys.argv) > 2 else "postgres"
            show_original_example()
            show_transformation_comparison(dialect)
        
        elif command == "full":
            dialect = sys.argv[2] if len(sys.argv) > 2 else "postgres"
            show_full_transformation(dialect)
        
        elif command == "all":
            show_original_example()
            run_all_dialects_demo()
        
        elif command == "perf":
            run_performance_demo()
        
        elif command == "convert":
            if len(sys.argv) > 2:
                dialect = sys.argv[2]
                show_full_transformation(dialect)
            else:
                print("‚ùå –£–∫–∞–∂–∏—Ç–µ –¥–∏–∞–ª–µ–∫—Ç: python hybrid_transpiler_demo.py convert <–¥–∏–∞–ª–µ–∫—Ç>")
        
        else:
            print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞: {command}")
    else:
        print("\n‚ö†Ô∏è  –£–∫–∞–∂–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É. –î–ª—è —Å–ø—Ä–∞–≤–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤.")

if __name__ == "__main__":
    main()



